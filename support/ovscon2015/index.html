---
layout: page
status: publish
published: true
title: Open vSwitch 2015 Fall Conference
author:
  display_name: admin
  login: admin
  email: jpettit@nicira.com
  url: ''
author_login: admin
author_email: jpettit@nicira.com
categories:
- Uncategorized
tags: []
comments: []
---
<p>
  The Open vSwitch 2015 Fall Conference will be held at the San Jose
  Doubletree on November 16 and 17, 2015.  All tickets are currently
  ``sold out,'' but you may add yourself to the wait list and find
  more information
  <a href=https://www.eventbrite.com/e/open-vswitch-fall-2015-conference-tickets-18029784571>here</a>.
</p>

<h1>Tentative Schedule</h1>

<p>
  Details of the schedule may still change.  Talks have not yet been
  assigned to particular time slots.
</p>

<table border=1>
  <tr>
    <th colspan=2><a name="day1">Monday, Nov. 16, 2015:</a></th>
  </tr>
  <tr>
    <td>8:00-8:45</td>
    <td>Breakfast and registration</td>
  </tr>
  <tr>
    <td>8:45-9:00</td>
    <td>Welcome</td>
  </tr>
  <tr>
    <td>9:00-9:30</td>
    <td>Keynote (Chris Wright, Red Hat)</td>
  </tr>
  <tr>
    <td>9:30-10:00</td>
    <td>Introduction to OVN, the Open Virtual Network for Open vSwitch</td>
  </tr>
  <tr>
    <td>10:00-10:15</td>
    <td>Break</td>
  </tr>
  <tr>
    <td>10:15-11:30</td>
    <td>
      <a href="#talks1">Talks, Session 1</a>:<br>
      <b>Geneve: What is it and why is OVN using it?</b> (Jesse Gross,
	VMware)<br>
      <b>Network Service Headers: Additions to OvS to support Service
	  Function Chaining in the kernel and userspace datapaths</b> (Uri
	Elzur, Intel; Thomas Graf, Noiro Networks)<br>
      <b>Using Open vSwitch to realize NFV and service chaining in a
	  Carrier Network</b> (Jeff Peterson, Entry Point)
    </td>
  </tr>
  <tr>
    <td>11:30-12:40</td>
    <td>Lunch</td>
  </tr>
  <tr>
    <td>12:40-2:20</td>
    <td>
      <a href="#talks2">Talks, Session 2</a>:<br>
      <b>MidoNet and the OpenVSwitch Datapath</b> (Duarte Nunes, Midokura)<br>
      <b>Mininet and Open vSwitch</b> (Bob Lantz, ON.Lab)<br>
      <b>OVS and L7 classification (DPI) use cases and demos: L7 stateful
	firewall, L7 QoS, L7 service chaining</b> (Franch Baudin, Qosmos)<br>
      <b>Implementing OpenFlow on a hardware switch</b> (Tony van der
      Peet, Allied Telesis)
    </td>
  </tr>
  <tr>
    <td>2:20-3:05</td>
    <td>Ice cream social</td>
  </tr>
  <tr>
    <td>3:05-4:45</td>
    <td>
      <a href="#talks3">Talks, Session 3</a>:<br>
      <b>Untangle complex network setups</b> (Rashid Khan and Jiri Benc,
      Red Hat)<br>
      <b>New OVS instrumentation features aimed at real-time monitoring
	of virtual networks</b> (Peter Phaal, InMon)<br>
      <b>A Proposal for Using TC Classification with Open vSwitch</b>
      (Simon Horman, Netronome)<br>
      <b>The State of Stateful Services</b> (Joe Stringer and Jarno
      Rajahalme, VMware)
    </td>
  </tr>
  <tr>
    <td>4:45-5:00</td>
    <td>Closing</td>
  </tr>
  <tr>
    <th colspan=2><a name="day2">Tuesday, Nov. 17, 2015:</a></th>
  </tr>
  <tr>
    <td>8:00-8:45</td>
    <td>Breakfast and registration</td>
  </tr>
  <tr>
    <td>8:45-10:05</td>
    <td>
      <a href="#talks4">Talks, Session 4</a>:<br>
      <b>How hot is the OVN?</b> (James H. Chou, IBM)<br>
      <b>OVS, OVN and Containers</b> (Gurucharan Shetty, VMware)<br>
      <b>Using Open vSwitch with Kubernetes, OpenShift, and
	Containers</b> (Dan Williams, Red Hat<br>
      <b>Enabling extensibility of the OVN logical pipeline</b> (Liran
      Schour, IBM)<br>
      <b>Integrating External SDN Applications with OVN without code change</b> (Gal Sagie, Huawei)
    </td>
  </tr>
  <tr>
    <td>10:05-10:25</td>
    <td>Break</td>
  </tr>
  <tr>
    <td>10:25-11:15</td>
    <td>
      <a href="#talks5">Talks, Session 5</a>:<br>
      <b>Characterizing the performance of the virtual switch within
	OPNFV</b> (Maryam Tahhan, Intel)<br>
      <b>Open vSwitch for OPNFV, The new OPNFV project and DPDK</b> (Mark
      D. Gray, Intel; Thomas F. Herbert, Red Hat)<br>
      <b>An Automation Framework and Methodology for Measuring OVS
	Performance</b> (Ying Chen, Mark Hamilton, and Vasmi Abidi,
      VMware)
      </td
  </tr>
  <tr>
    <td>11:15-11:40</td>
    <td>Game-show style trivia contest</td>
  </tr>
  <tr>
    <td>11:40-12:55</td>
    <td>Lunch</td>
  </tr>
  <tr>
    <td>12:55-1:35</td>
    <td>Lightning talks</td>
  </tr>
  <tr>
    <td>1:35-2:50</td>
    <td>
      <a href="#talks6">Talks, Session 6</a>:<br>
      <b>Open vSwitch Enhancements for Netdev DPDK</b> (Gerald Rogers,
	Intel)<br>
      <b>OVS, DPDK and Software Dataplane Acceleration</b> (Mark D. Gray
and Kevin Traynor, Intel; Thomas F. Herbert, Red Hat)<br>
      <b>DPDK Data Plane Development Kit: Performance Optimization
Techniques</b> (Muthurajan Jayakumar, Intel)<br>
      <b>FM10K: Acceleration of Network Virtualized Workloads with a
	25G/100G Network Adapter</b> (Dan Daly, Intel)
    </td>
  </tr>
  <tr>
    <td>2:50-3:05</td>
    <td>Break</td>
  </tr>
  <tr>
    <td>3:05-4:45</td>
    <td><a href="#talks7">Talks, Session 7</a>:<br>
      <b>OVS Datapath Specialization using P4</b> (Muhammad Shahbaz,
      Princeton)<br>
      <b>C like DSL for Open vSwitch</b> (Saurabh Shrivastava, Nuage Networks)<br>
      <b>Linux network namespaces support in Open vSwitch</b> (Jiri Benc,
      Red Hat)<br>
      <b>Match: A Generic Packet Processing Pipeline Runtime Integrated
	with OvS</b> (Hao Zheng, Intel)
    </td>
  </tr>
  <tr>
    <td>4:45-5:00</td>
    <td>Closing</td>
  </tr>
</table>

<h1><a name="talks1" href="#day1">Talks, Session 1</a></h1>

<h2><b>Geneve: What is it and why is OVN using it?</b> (Jesse Gross,
VMware)</h2>

<p>
  OVN has adopted the Geneve protocol as its primary encapsulation
  format between hypervisors. While not as well known as VXLAN, Geneve
  is designed to be a more futureproof superset of VXLAN's features and
  is supported by a wide array of both software and hardware
  makers. This flexibility is already being used by OVN to build a
  pipeline that is both more powerful and simpler than what could be
  done before. To better understand why Geneve came into existence, the
  talk will give an overview of the protocol itself and its
  capabilities. We'll then take a look at its support in OVN as well as
  other implementations and where it might go in the future.
</p>

<h2><b>Network Service Headers: Additions to OvS to support Service
Function Chaining in the kernel and userspace datapaths</b> (Uri
Elzur, Intel; Thomas Graf, Noiro Networks)</h2>

<p>
  In this talk we will review the contributions made to Open vSwitch
  to support Network Service Headers (NSH) based SFC (Service Function
  Chaining) into the kernel and DPDK accelerated userspace datapaths.
  For the handling of NSH, OvS must be able to:
</p>

<ul>
  <li>
    Act as Openflow classifier to classify packets that need to be
    pushed through a service function chain and add the requisite NSH
    header. This header allows the infrastructure to sequence this
    frame through the different services it requires.
  </li>

  <li>
    Acts as a Service Function Forwarder (SFF) which steers an NSH
    encapsulated frame to the next service, by looking at the NSH
    service path and service index to determine how the frame should
    be forwarded.
  </li>

  <li>
    Provides a mechanism allowing NSH encapsulated frame to carry
    shared metadata between service functions along the instantiated
    service path.
  </li>
</ul>

<p>
  The configuration interface uses a combination of OpenFlow and OVSDB
  to allow control and orchestration layers to program these service
  chains into Open vSwitch.  We will discuss the details of the
  patches submitted to OvS, compare the kernel and DPDK accelerated
  userspace modes in terms of performance and capability, and discuss
  the pressing needs for service function chaining today both in the
  Data Center and Telco markets. We also intend to discuss and share
  future plans for NSH in OvS, which includes OAM support, variable
  metadata length support, and the continuous optimization of
  forwarding performance.
</p>

<h2><b>Using Open vSwitch to realize NFV and service chaining in a
Carrier Network</b> (Jeff Peterson, Entry Point)</h2>

<p>
  This presentation will explore an Optical Network Terminal (ONT)
  replacement that provides cloud functionality at the subscriber edge
  in a carrier network.  The new ONT - a Virtual Broadband Gateway (VBG)
  - is used to transform an incoming optical signal to an electrical
  and/or wireless signal for voice, data, and other services.  The VBG
  is a single instance of hardware that is used to create multiple
  virtual routers, switches, and service demarcations using Open
  vSwitch, NVF, and SFC (Service Function Chaining). The VBG is being
  used to simplify the network at the subscriber premise and to provide
  a point of presence at the premise for all of the network stakeholders
  (network operator, service provider, and subscriber).
</p>

<p>
  The VBG includes the following features:
</p>  

<ul>
   <li>Linux based OS</li>
   <li>Dataplane - Open vSwitch</li>
   <li>OpenFlow capable</li>
   <li>Supports multiple virtual machines (Cloud at the Edge)</li>
   <li>Supports Service Function Chaining (SFC)</li>
   <li>Supports Network Functions Virtualization (NFV)</li>
   <li>Supports software (CPU) switching</li>
   <li>Supports Trusted Platform Module (TPM)</li>
   <li>Supports Virtual Analog Terminal Adapter (V-ATA)</li>
</ul>

<h1><a name="talks2" href="#day1">Talks, Session 2</a></h1>

<h2><b>MidoNet and the OpenVSwitch Datapath</b> (Duarte Nunes, Midokura)</h2>

<p>
  MidoNet, an open source virtual network platform, uses the
  OpenVSwitch kernel module as it's datapath, relying on it not only
  for packet switching and decision caching, but also as an efficient
  way to implement features like flow tracing and congestion analysis.
</p>

<p>
  In this talk we'll go over the basics of how MidoNet interacts with
  the kernel module and manages installed flows. We'll cover how
  mechanisms such as megaflows and connection tracking are leveraged
  to power some of MidoNet's features. Finally, we'll also present
  some performance considerations stemming from the ways the datapath
  is employed.
</p>

<h2><b>Mininet and Open vSwitch</b> (Bob Lantz, ON.Lab)</h2>

<p>
  Mininet is an emulation framework that quickly creates virtual
  networks of hosts, switches, and SDN controllers on your laptop for
  development, research, teaching, or any other use. For scalability,
  Mininet hosts are usually just processes in network namespaces,
  connected to software switches (typically Open vSwitch) via virtual
  Ethernet links.
</p>

<p>
  In this talk, I will provide a brief overview and demonstration of
  Mininet, describe how it uses Open vSwitch, and present some
  experiences so far and thoughts on how OVS might evolve to support
  the use case of network emulation.
</p>

<h2><b>OVS and L7 classification (DPI) use cases and demos: L7 stateful
firewall, L7 QoS, L7 service chaining</b> (Franch Baudin, Qosmos)</h2>

<p>
  L7 classification with OVS without patch is now possible thanks to
  conntrack framework and well-crafted OVS rules. The basic idea is to
  rely on a userland L7 classifier, typically based on a DPI engine,
  marking the conntracks with L7 classification. Thanks to the new
  connmark and connlabel matchers, holding the L7 classification
  thanks to the L7 application mentioned previously, we can craft L7
  OVS rules.
</p>

<p>
  This presentation will explains and demonstrate the asynchronous
  design of L7 classification in two basic use cases:
</p>

<ol>
  <li> Qos: bittorrent rate limiting, ftp rate limiting</li>
  <li> L7 Firewall: bittorrent denial, ssh on non-regular ports denial</li>
</ol>

<p>
  For the demo part, one client VM and one server VM will be
  interconnected by OVS, with L7 rules applied on the server port
  (typical micro-segmentation use case).  There will be no OpenStack
  neither OpenDayLight for this part, just KVM/virsh/namespaces and
  OVS.
</p>

<p>
  The second part of the talk will demonstrate, on the same laptop,
  with the same OVS, a service chaining use case with VMs managed by
  OpenStack Kilo (vanilla, no patch) and Service Chaining managed by
  OpenDayLight Lithium (vanilla, no patch). The rationales of the
  technical choices will be explained: why no NSH, what about an NFV
  use case with DPDK OVS, what about using OVS as a ServiceClassifier
  and/or as a ServiceFunctionForwarder, what about a real NFV
  deployment ingredients, ...
</p>

<h2><b>Implementing OpenFlow on a hardware switch</b> (Tony van der
Peet, Allied Telesis)</h2>

<p>
  I will share my experience of implementing OpenFlow on a hardware
  switch, using OpenVSwitch, and describe the main lessons
  learned. Then I will discuss future plans, involving TTPs, a new
  ofproto and OF-DPA.
</p>

<h1><a name="talks3" href="#day1">Talks, Session 3</a></h1>

<h2><b>Untangle complex network setups</b> (Rashid Khan and Jiri Benc,
Red Hat)</h2>

<p>
  While debugging networking related problems on modern cloud and
  container based solutions, one often finds oneself trapped in a maze
  of Open vSwitch bridges combined with regular bridges, tunnels, veth
  pairs and network namespaces with tens or hundreds of network
  interfaces. The relationship between those is usually anything but
  clear.
</p>

<p>
  The talk will present plotnetcfg, an open source tool to visualy
  represent relationship between network interfaces on a single host,
  including Open vSwitch bridges. To illustrate the complexity of
  current Open vSwitch users, some of the more interesting setups seen
  in the wild will be shown and described.
</p>

<h2><b>New OVS instrumentation features aimed at real-time monitoring
of virtual networks</b> (Peter Phaal, InMon)</h2>

<p>
  The talk will describe the recently added packet-sampling mechanism
  that returns the full list of OVS actions from the kernel.  A
  demonstration will show how the OVS sFlow agent uses this mechanism to
  provide real-time tunnel visibility.  The motivation for this
  visibility will be discussed, using examples such as end-to-end
  troubleshooting across physical and virtual networks, and tuning
  network packet paths by influencing workload-placement in a
  VM/Container environment.
</p>

<h2><b>A Proposal for Using TC Classification with Open vSwitch</b>
(Simon Horman, Netronome)</h2>

<p>
  The traffic control (TC) framework of the Linux Kernel provides a
  rich set of components for packet control and classification.
  Recent work in TC with the eBPF classifier has highlighted the
  richness of this framework and raises the question of how TC could
  be leveraged to offload classification from Open vSwitch.  In such a
  model, TC could also serve as an abstraction layer where
  classification could seamlessly be offloaded to other devices, such
  as an intelligent NIC, through the use of eBPF.  This presentation
  will explore these offload opportunities and suggest ways in which
  OVS may benefit from leveraging TC classification.
</p>

<h2><b>The State of Stateful Services</b> (Joe Stringer and Jarno
Rajahalme, VMware)</h2>

<p>
  Last year, we outlined plans to build out support for connection
  tracking in OVS and described multiple potential users of this
  functionality - ranging from stateful firewalling to NAT and
  DPI. This talk provides an overview of what has been merged today,
  and takes a look at the next steps for extending OVS stateful
  service support.
</p>

<h1><a name="talks4" href="#day2">Session 4</a></h1>

<h2><b>How hot is the OVN?</b> (James H. Chou, IBM)</h2>

<p>
  OVN brings much-needed support for a native virtualization layer to
  the datacenter, with the goal of providing native support for
  virtual networking abstractions that are production quality and can
  scale. But how much can it really scale? Ideally we'd like to have
  just one virtual network fabric in a datacenter, but that seems
  unachievable with the current design - the OVN architecture paper
  describes a network consisting of a mere few thousands of servers as
  a large network.
</p>

<p>
  We describe our observations of OVN behavior both in actual (test)
  OpenStack deployments of various sizes as well as the test harness
  we use to simulate logical and physical networks of various
  sizes. Our focus is on characterizing the growth characteristics in
  CPU, filesystem I/O, and network traffic with the growth in number
  of chassis, focusing both on initial power-on (following, say, an
  unexpected power loss to multiple racks of servers) as well as
  performance changes due to logical network changes as the number of
  chassis grows. We pinpoint bottlenecks in OVN, both expected
  (ovsdb-server) and unexpected, with the goal of identifying areas
  which must be improved in order to provide high availability and
  scalability to at least tens, if not hundreds, of thousands of
  servers.
</p>

<p>
  This abstract describes work which is getting underway. We expect to
  have results before the conference.
</p>

<h2>Joint Talk:</h2>

<blockquote>
<p><b>OVS, OVN and Containers</b> (Gurucharan Shetty, VMware)</p>

<p>
  This talk focuses on containers landscape like Docker, Kubernetes
  etc and how OVS and OVN can be used to provide container networking.
</p>

<p><b>Using Open vSwitch with Kubernetes, OpenShift, and
Containers</b> (Dan Williams, Red Hat</p>

<p>
  We're using Open vSwitch and VXLAN tunnels to provide isolated,
  multi-tenant network connectivity between containers in a
  Kubernetes/OpenShift cloud.  OVS provides the flexibility to easily
  isolate traffic between containers, nodes, and external resources,
  and allows flexible linkage of containers on different nodes into
  one public-facing service.  Come learn about our experiences with
  VXLAN performance and NIC offload, optimizing OpenFlow rules for
  faster container spin-up, and our Open vSwitch network architecture
  in the OpenShift platform.
</p>
</blockquote>

<h2>Joint Talk:</h2>

<blockquote>
<p><b>Enabling extensibility of the OVN logical pipeline</b> (Liran
Schour, IBM)</p>

<p>
  In this talk we discuss the need to enable flexible construction of
  the OVN processing pipeline. In addition, we describe an example
  where this feature can be used and propose a path to implementation.
  Currently, OVN implements a fixed logical pipeline composed from
  several stages. Each pipeline stage, assigned with a unique table
  id, is translated into a flow table configured on every OVS instance
  by the ovn-controller. In some cases, however, an external entity
  with out-of-band knowledge needs to impose workflow-specific actions
  on some flows. To grow the OVN ecosystem, it can be beneficial to
  enable 3rd party components to change the logical pipeline by adding
  new stages.
</p>

<p>
  We describe an example of such a component that detects elephant
  flows by sflow monitoring from overlay edges and marks them for
  differentiated processing in the physical forwarding plane. When
  detected, elephant flows are being marked by adding logical flows
  that set DSCP field to a specific value. Physical forwarding plane
  then uses these marks to separate elephants flows from the rest,
  e.g. by sending them over ad-hoc optical circuits or over
  specialized DCI links.  Implementation-wise, we propose to extend
  the current fixed logical pipeline to be flexible by providing a SB
  control API whereby entities external to the OVN control plane can
  add new pipeline stages. As a result, external loosely coupled
  entities will be be able to define new flow tables where
  workload-specific logical flows can be added.
</p>

<p><b>Integrating External SDN Applications with OVN without code change</b> (Gal Sagie, Huawei)</p>

<p>
  Integrating external applications without changing code is possible
  in OVN by modifying the Southbound DB Pipeline table.  In this talk
  we will present some examples of using this approach to implement
  interesting networking applications.  We will also describe another
  approach that allows reactiveness in the model and hence simpler to
  develop more sophisticated external network services and
  applications, and how it can be implemented in OVN.
</p>
</blockquote>

<h1><a href="#day2" name="talks5">Session 5</a></h1>

<h2>Joint Talk:</h2>

<blockquote>
<p><b>Characterizing the performance of the virtual switch within
OPNFV</b> (Maryam Tahhan, Intel)</p>

<p>
  Virtual switches have been long recognized as an essential component
  of the virtual network in the data centre, and are growing in
  popularity in the telecoms sector. Exploding traffic is creating
  extraordinary demand on the network and with that, exceptional
  performance requirements for the interfaces into Virtual Network
  Functions in the NFVI. One such interface is the virtual switch, thus
  it is crucial to be able to characterize its performance in order to
  determine its capabilities and suitability for deployment in Telco NFV
  environments. This talk looks at the work undertaken by the OPNFV
  VSPERF project to define a test suite for characterizing the
  performance of the virtual switch and any considerations that must be
  taken into account when doing so.
</p>

<p><b>Open vSwitch for OPNFV, The new OPNFV project and DPDK</b> (Mark
D. Gray, Intel; Thomas F. Herbert, Red Hat)</p>

<p>
  This talk is about Open vSwitch with a software accelerated data
  plane (DPDK) and the OPNFV project. OVS for OPNFV is not a
  development project. It is a new project in OPNFV to deploy OVS with
  software accelerated data plane for NFV deployments for telcos and
  similar users.
</p>

<p>
  We will begin by introducing Open Platform for NFV (OPNFV.) The focus will be
  on the the goals for the OVS in OPNFV and how we hope to generate feedback to
  upstream DPDK and OVS projects. We will discuss the usability of OVS/DPDK in
  real-world deployment environments. Also, we will discuss both the short-term
  goals for the OVS for OPNFV project in the next release of OPNFV, Brahmaputra
  and the goals beyond this first release.
</p>

<p>
  The OVS for OPNFV project provides specific deployments of OVS/DPDK
  utilizing complex Cloud and NFV high performance networking
  environments. Included will be packaging challenges, and specifics
  of how we plan to deploy OVS/DPDK as an alternate OVS package. We
  will talk about our hopes to obtain performance results oriented
  toward SFC deployments and how this will benefit the OVS/DPDK
  communities.
</p>

<p>
  Finally, the talk will conclude with our experience so far with OVS for OPNFV
  and the outlook for the future of NFV including needed improvements in
  OVS/DPDK needed by NFV and SFC.
</p>
</blockquote>

<h2><b>An Automation Framework and Methodology for Measuring OVS
Performance</b> (Ying Chen, Mark Hamilton, and Vasmi Abidi,
VMware)</h2>

<p>
  We will present our methodology and test design for measuring
  performance of OVS.
</p>

<p>
  We use a combination of Ansible and other open-source tools for
  orchestrating configuration management, organizing tests, and
  storing results.
</p>

<p>
  We use this framework to routinely run repeatable, reliable
  performance tests using both software tools (e.g. netperf in a VM)
  and hardware tools (e.g.  RFC2544 tests with Spirent).
</p>

<p>
  We will discuss how to configure the system (Linux and OVS) for
  achieving maximum performance on multicore machines, and how to tune
  to get consistent results. Consistent numbers are important to be
  able to detect performance regressions across different builds.
</p>

<p>
  We will present results to compare performance of KVM OVS with
  different data paths.
</p>

<h1><a href="#day2" name="talks6">Session 6</a></h1>

<h2><b>Open vSwitch Enhancements for Netdev DPDK</b> (Gerald Rogers,
Intel)</h2>

<p>
  This presentation will cover the latest enhancements to OpenvSwitch
  with Netdev-DPDK that have been developed over the past couple of
  quarters.  Specifically we would discuss the additional new
  features, performance enhancements and future features.  Intel
  continues to add new features at a regular cadence to enhance the
  user space capabilities.  Recent enhancements include QOS,
  Statistics, and useability.  OpenvSwitch with Netdev-DPDK has
  achieved greater than 10x the performance of kernel based
  OpenvSwitch. The presentation will discuss recent performance
  changes in DPDK and other performance modifications to the User
  Space processing.  The presentation would include the latest
  performance we have achieved, and future performance targets.
</p>

<h2>Joint Talk:</h2>

<blockquote>
<p><b>OVS, DPDK and Software Dataplane Acceleration</b> (Mark D. Gray
and Kevin Traynor, Intel; Thomas F. Herbert, Red Hat)</p>

<p>
  This talk is about Open vSwitch with netdev DPDK.
</p>  

<p>
  Currently DPDK presents the best alternative high speed software
  data path for support of high speed interfaces in OVS. We have seen
  DPDK/OVS provide throughput that can compete with hardware switching
  fabrics at close to 40Gb line rates. However, DPDK presents
  challenges when compared with the Linux kernel datapath. DPDK lacks
  refinements available from over 20 years of development of Linux
  kernel networking and devices. Different semantics in DPDK for
  provisioning interfaces, the user experience in that they need
  extensive architecture knowledge for optimum performance, and a
  challenging debugging environment are a few of these challenges.
</p>

<p>
  For those less familiar, we will begin our talk with a discussion of
  how DPDK integrates with OVS by way of the netdev API. We will cover
  how to use, deploy and debug OVS with DPDK. issues of achieving high
  performance in real-world scenarios such as host-guest, and guest to
  guest.
</p>

<p>
  Finally, the talk about the future of supporting ever higher demands for fast
  packet switching in OVS and the role of DPDK and other paradigms for
  acceleration.
</p>

<p><b>DPDK Data Plane Development Kit: Performance Optimization
Techniques</b> (Muthurajan Jayakumar, Intel)</p>

<p>
  All developers and customers know that DPDK delivers significantly
  higher performance compared to native Linux driver. How does DPDK
  deliver such a great performance with small packet sizes?  In this
  talk, we will emphasize top three performance optimization
  techniques that address
</p>

<ul>
  <li>
    Core related optimizations in a multi-core environment - to
    improve IPC (inter processor communication) performance,
  </li>

  <li>
    Memory related optimizations - hiding the latency with s/w
    prefetch techniques and
  </li>

  <li>
    Network i/o related optimizations - amortizing the PCIe bus
    overhead.
  </li>
</ul>

<p>
  We will refer to real sample code examples that utilize all the
  above techniques.
</p>

<p>
  The audience will be exposed to DPDK microbenchmarks that will help
  the audience in profiling their applications and platforms while
  building and integrating DPDK applications.
</p>
</blockquote>

<h2><b>FM10K: Acceleration of Network Virtualized Workloads with a
25G/100G Network Adapter</b> (Dan Daly, Intel)</h2>

<p>
  In this talk we will demonstrate the use of Intel(r) FM10000 based
  Ethernet adapters to accelerate workloads running over network
  virtualized infrastructure on standard high volume servers.  Using
  Open vSwitch as the control point, these network adapters are able
  to accelerate the usage of virtual L2/L3 networks, ACLs applied
  across virtual domains, Network Address Translation and Service
  Function Chaining.  When used in conjunction with an accelerated
  OvS, individual virtual network functions (VNFs) can use DPDK to set
  up filtering and traffic management functions to efficiently scale
  up to 100Gbs going into a single VNF, or into a set of VNFs working
  in concert.  We will share performance results that demonstrate the
  efficient usage of a virtualized platform at 100Gb Ethernet line
  rates, and discuss the OvS implications of leveraging these platform
  specific capabilities.
</p>

<h1><a href="#day2" name="talks7">Session 7</a></h1>

<h2><b>OVS Datapath Specialization using P4</b> (Muhammad Shahbaz,
Princeton)</h2>

<p>
  Unlike OpenFlow, which provides a *pipelined* match-action table
  (MAT) abstraction, the native Open vSwitch (OVS) itself, on the
  other hand, provides a *pool* of MATs for the user to program. There
  is no inherent notion of a pipeline and it's the responsibility of
  the user to not only maintain tables' state but also explicitly
  construct the pipeline by installing carefully crafted flow rules at
  runtime. This abstraction, though very powerful, makes it hard to
  manage the switch as the number of MATs increase. P4 helps solve
  this problem by enabling users to statically define MAT pipelines as
  P4 programs and letting them only manage the tables' state at
  runtime. This has many benefits and, furthermore, with a P4 program
  one can also specialize OVS to implement only the required features
  like parsing Ethernet headers and not IP headers in case of layer2
  forwarding. In this talk, we will list these benefits and share our
  experience of compiling P4 to OVS.
</p>

<h2><b>C like DSL for Open vSwitch</b> (Saurabh Shrivastava, Nuage Networks)</h2>

<p>
  OVS can be abstracted as a stack based processor with a set of
  registers, RAM and with an instruction set for function calls,
  conditional and unconditional jumps, memory load and stores, logical
  operators such as ||, &&, !. This processor can now be programmed in
  C (with restrictions).
</p>

<p>
  The programming model is that a packet enters the processing
  pipeline at the "main" function, does several function calls,
  lookups RAM, eventually modifying packet by writing into well known
  "global" variables which correspond to flow fields.
</p>

<p>
  The code section is implemented in table 0, RAM in table 1. REG0 is
  used as the "program counter", function call parameters are loaded
  into registers, return value of the function is pushed on to the
  stack, conditional jump is implemented by playing with rule
  priority.
</p>

<h2><b>Linux network namespaces support in Open vSwitch</b> (Jiri Benc,
Red Hat)</h2>

<p>
  The Linux kernel provides network namespaces (netns) as a facility to
  partition the networking stack. Although Open vSwitch has a
  rudimentary support for bridges spanning several network namespaces,
  the support is incomplete. This often leads to surprising results and
  things not working as expected.
</p>

<p>
  The talk will present the major problems with netns support in Open
  vSwitch and propose options to solve them. Some of the problems can be
  addressed using mechanisms that the kernel already provides, for some
  of them new API will be needed.
</p>

<h2><b>Match: A Generic Packet Processing Pipeline Runtime Integrated
with OvS</b> (Hao Zheng, Intel)</h2>

<p>
  In this talk we discuss Match, a generic interface for capability
  discovery and state management of a match-action based packet
  processing pipeline, and how this can be used to accelerate Open
  vSwitch.  Match fills a role on a programmable platform where
  optimized pipelines outside of OvS can be leveraged, such as
  optimized software pipelines and hardware acceleration devices.  We
  will share some of the integration done with OvS, including the
  ability for OvS to leverage external TCAM and hash lookup resources,
  the ability for OvS to offload VXLAN encap / decap, and the ability
  to control the packet forwarding of packets going in and out of a
  hardware virtual functions (VFs) into VMs and containers.
</p>

<p>
  This talk continues on the discussion we had in the last OvS
  conference, in the last pair of LinuxCons, and some discussions at
  the P4 conference on a runtime for programmable pipelines.
</p>













